// src/pages/TopicDetailPage.jsx
import React, { useEffect, useState, useRef } from "react";
import { useParams, useNavigate } from "react-router-dom";
import { Spin, message, Tooltip, Tag } from "antd";
import { LeftOutlined } from "@ant-design/icons";
import "../css/topic-detail.css";

import { VocabularyApi } from "../services/api/vocabularyApi";
import { TopicsApi } from "../services/api/topicsApi";

/* --- ICONS SVG --- */
const MicIcon = ({ color }) => (
  <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
    <path d="M12 15C13.66 15 15 13.66 15 12V6C15 4.34 13.66 3 12 3C10.34 3 9 4.34 9 6V12C9 13.66 10.34 15 12 15Z" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
    <path d="M19 10V12C19 15.87 15.87 19 12 19C8.13 19 5 15.87 5 12V10" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
    <path d="M12 19V22" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
  </svg>
);

const SpeakerIcon = ({ color }) => (
  <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
    <path d="M11 5L6 9H2V15H6L11 19V5Z" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
    <path d="M19.07 4.93C20.98 6.84 20.98 9.95 19.07 11.86" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
    <path d="M15.54 8.46C15.93 8.85 15.93 9.49 15.54 9.88" stroke={color || "currentColor"} strokeWidth="1.5" strokeLinecap="round" strokeLinejoin="round"/>
  </svg>
);

export default function TopicDetailPage() {
  const { id } = useParams();
  const navigate = useNavigate();

  // Data State
  const [topic, setTopic] = useState(null);
  const [vocabList, setVocabList] = useState([]);
  const [loading, setLoading] = useState(true);

  // Learning State
  const [selectedVocab, setSelectedVocab] = useState(null);
  const [isModalOpen, setIsModalOpen] = useState(false);
  
  // Recording State
  const [isRecording, setIsRecording] = useState(false);
  const [feedback, setFeedback] = useState(null); // K·∫øt qu·∫£ ch·∫•m ƒëi·ªÉm: { type: 'success' | 'error', text: '...' }
  
  // Ref ƒë·ªÉ l∆∞u tr·ªØ ƒë·ªëi t∆∞·ª£ng Recognition (tr√°nh t·∫°o l·∫°i nhi·ªÅu l·∫ßn)
  const recognitionRef = useRef(null);

  // --- 1. INITIAL LOAD ---
  useEffect(() => {
    const fetchData = async () => {
      try {
        setLoading(true);
        const [topicRes, vocabRes] = await Promise.all([
            TopicsApi.getById(id),
            VocabularyApi.getAll({ topic_id: id, limit: 100 })
        ]);
        setTopic(topicRes);
        setVocabList(vocabRes.data);
      } catch (error) {
        message.error("Kh√¥ng t√¨m th·∫•y ch·ªß ƒë·ªÅ ho·∫∑c l·ªói k·∫øt n·ªëi");
        navigate("/topics");
      } finally {
        setLoading(false);
      }
    };
    if (id) fetchData();
  }, [id, navigate]);

  // --- 2. H√ÄM X·ª¨ L√ù √ÇM THANH (QUAN TR·ªåNG) ---

  // A. Text-to-Speech (ƒê·ªçc t·ª´ v·ª±ng)
  const handleSpeak = (text) => {
    if (!window.speechSynthesis) {
        message.error("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ph√°t √¢m!");
        return;
    }
    // D·ª´ng √¢m thanh ƒëang ƒë·ªçc d·ªü
    window.speechSynthesis.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "ja-JP"; // Gi·ªçng Nh·∫≠t
    utterance.rate = 0.8;     // T·ªëc ƒë·ªô ch·∫≠m v·ª´a ph·∫£i
    window.speechSynthesis.speak(utterance);
  };

  // B. Speech-to-Text (Thu √¢m & Ki·ªÉm tra ph√°t √¢m)
  const handleRecord = () => {
    // Ki·ªÉm tra tr√¨nh duy·ªát c√≥ h·ªó tr·ª£ kh√¥ng
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      message.error("Tr√¨nh duy·ªát n√†y kh√¥ng h·ªó tr·ª£ thu √¢m (D√πng Chrome/Edge nh√©!)");
      return;
    }

    if (isRecording) {
      // N·∫øu ƒëang ghi √¢m th√¨ b·∫•m l·∫ßn n·ªØa ƒë·ªÉ d·ª´ng
      recognitionRef.current?.stop();
      setIsRecording(false);
      return;
    }

    // B·∫Øt ƒë·∫ßu ghi √¢m
    setFeedback(null); // Reset k·∫øt qu·∫£ c≈©
    setIsRecording(true);

    const recognition = new SpeechRecognition();
    recognitionRef.current = recognition;
    
    recognition.lang = "ja-JP"; // Ng√¥n ng·ªØ l·∫Øng nghe: Ti·∫øng Nh·∫≠t
    recognition.continuous = false; // Ng·∫Øt ngay khi n√≥i xong c√¢u
    recognition.interimResults = false;

    recognition.onstart = () => {
      // B·∫Øt ƒë·∫ßu thu...
    };

    recognition.onresult = (event) => {
      const transcript = event.results[0][0].transcript; // L·∫•y vƒÉn b·∫£n m√°y nghe ƒë∆∞·ª£c
      console.log("User said:", transcript);
      
      // LOGIC CH·∫§M ƒêI·ªÇM
      checkPronunciation(transcript);
    };

    recognition.onerror = (event) => {
      console.error("L·ªói thu √¢m:", event.error);
      setIsRecording(false);
      setFeedback({ type: 'error', text: "Kh√¥ng nghe r√µ, h√£y th·ª≠ l·∫°i!" });
    };

    recognition.onend = () => {
      setIsRecording(false);
    };

    recognition.start();
  };

  // C. H√†m so s√°nh k·∫øt qu·∫£
  const checkPronunciation = (userSpoke) => {
    if (!selectedVocab) return;

    // Chu·∫©n h√≥a chu·ªói (b·ªè d·∫•u c√°ch th·ª´a, ƒë∆∞a v·ªÅ ch·ªØ th∆∞·ªùng)
    const targetWord = selectedVocab.word.trim(); // V√≠ d·ª•: Êó•Êú¨
    const targetReading = selectedVocab.reading.trim(); // V√≠ d·ª•: „Å´„Åª„Çì
    const userSpokeClean = userSpoke.trim();

    // So s√°nh: N·∫øu ng∆∞·ªùi d√πng n√≥i ƒë√∫ng Kanji HO·∫∂C n√≥i ƒë√∫ng Hiragana
    // (V√¨ Google Speech ƒë√¥i khi tr·∫£ v·ªÅ Kanji, ƒë√¥i khi tr·∫£ v·ªÅ Hiragana)
    if (userSpokeClean === targetWord || userSpokeClean === targetReading) {
      setFeedback({ 
        type: 'success', 
        text: `Tuy·ªát v·ªùi! B·∫°n n√≥i: "${userSpokeClean}" (Ch√≠nh x√°c)` 
      });
      // Ph√°t ti·∫øng 'ding' ch√∫c m·ª´ng (tu·ª≥ ch·ªçn)
    } else {
      setFeedback({ 
        type: 'error', 
        text: `Sai r·ªìi. B·∫°n n√≥i: "${userSpokeClean}". H√£y th·ª≠ l·∫°i!` 
      });
    }
  };


  // --- 3. UI HANDLERS ---
  const handleCardClick = (vocab) => {
    setSelectedVocab(vocab);
    setFeedback(null); // Reset feedback c≈©
    setIsModalOpen(true);
    handleSpeak(vocab.word); // T·ª± ƒë·ªông ƒë·ªçc khi m·ªü
  };

  const closeModal = () => {
    setIsModalOpen(false);
    setSelectedVocab(null);
    window.speechSynthesis.cancel(); // T·∫Øt ti·∫øng n·∫øu ƒëang ƒë·ªçc
    if (isRecording) recognitionRef.current?.stop();
  };

  if (loading) return <div className="loading-container"><Spin size="large" tip="ƒêang t·∫£i b√†i h·ªçc..." /></div>;

  return (
    <div className="detail-container">
      {/* HEADER */}
      <header className="detail-header">
        <button className="back-btn" onClick={() => navigate("/topics")}>
          <LeftOutlined /> Quay l·∫°i
        </button>
        <div className="header-info">
            <h1>{topic?.name}</h1>
            <span className="subtitle">{vocabList.length} t·ª´ v·ª±ng ‚Ä¢ {topic?.level}</span>
        </div>
      </header>

      {/* GRID T·ª™ V·ª∞NG */}
      <div className="vocab-grid">
        {vocabList.map((vocab) => (
          <div 
            key={vocab.id} 
            className="vocab-card"
            onClick={() => handleCardClick(vocab)}
          >
            <div className="card-main">{vocab.word}</div>
            <div className="card-sub">{vocab.reading}</div>
            <div className="card-meaning">{vocab.meaning}</div>
          </div>
        ))}
      </div>

      {/* MODAL FLASHCARD */}
      {isModalOpen && selectedVocab && (
        <div className="modal-overlay" onClick={closeModal}>
          <div className="modal-content" onClick={(e) => e.stopPropagation()}>
            <button className="close-btn" onClick={closeModal}>‚úï</button>
            
            <div className="flashcard-display">
              <div className="main-word">{selectedVocab.word}</div>
              
              <div className="action-row">
                 {/* N√öT LOA */}
                 <button className="icon-btn" onClick={() => handleSpeak(selectedVocab.word)}>
                    <SpeakerIcon />
                 </button>
                 
                 {/* N√öT MIC */}
                 <button 
                    className={`icon-btn ${isRecording ? 'recording' : ''}`} 
                    onClick={handleRecord}
                 >
                    <MicIcon />
                 </button>
              </div>

              {/* KHU V·ª∞C HI·ªÇN TH·ªä K·∫æT QU·∫¢ CHECK MIC */}
              {isRecording && (
                <div className="feedback-box listening">
                    ƒêang nghe... üé§
                </div>
              )}

              {feedback && !isRecording && (
                <div className={`feedback-box ${feedback.type}`}>
                    {feedback.text}
                </div>
              )}

              <div className="info-section">
                 <div className="reading-text">{selectedVocab.reading}</div>
                 <div className="meaning-text">{selectedVocab.meaning}</div>
              </div>

              {/* PH√ÇN T√çCH KANJI */}
              {selectedVocab.kanjiList && selectedVocab.kanjiList.length > 0 && (
                  <div className="kanji-breakdown-section">
                      <div className="section-title">Ph√¢n t√≠ch H√°n t·ª±:</div>
                      <div className="kanji-chips">
                          {selectedVocab.kanjiList.map(k => (
                              <Tooltip key={k.id} title={`${k.meanings?.join(", ")} (√Çm On: ${k.onyomi})`}>
                                  <Tag color="purple" style={{ fontSize: 16, padding: '4px 10px', cursor: 'pointer' }}>
                                      {k.kanji} - {k.meanings?.[0]}
                                  </Tag>
                              </Tooltip>
                          ))}
                      </div>
                  </div>
              )}
            </div>
          </div>
        </div>
      )}
    </div>
  );
}